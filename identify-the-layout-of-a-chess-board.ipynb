{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":275544,"sourceType":"datasetVersion","datasetId":115231}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T11:31:48.360024Z","iopub.execute_input":"2024-07-23T11:31:48.360382Z","iopub.status.idle":"2024-07-23T11:31:48.668939Z","shell.execute_reply.started":"2024-07-23T11:31:48.360354Z","shell.execute_reply":"2024-07-23T11:31:48.668155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this notebook, we train a CNN to detect the configuration of piecies on a chess board. The dataset consists of 80000 400x400 images of a chess board in 28 styles and with 5-15 pieces on it from one of 32 styles. The filename decribes the layout in standard PEN notation (pieces on each row, lower case is black, upper case is white, numbers indicate a number of consecutive empty squares). We could train a CNN on the images but it is probably more efficient to train a network on individual squares/pieces.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:31:49.885499Z","iopub.execute_input":"2024-07-23T11:31:49.886370Z","iopub.status.idle":"2024-07-23T11:31:53.074092Z","shell.execute_reply.started":"2024-07-23T11:31:49.886341Z","shell.execute_reply":"2024-07-23T11:31:53.073320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View the data","metadata":{}},{"cell_type":"markdown","source":"List of files:","metadata":{}},{"cell_type":"code","source":"files=glob(\"*.jpeg\",root_dir='/kaggle/input/chess-positions/train/')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:03.218260Z","iopub.execute_input":"2024-07-23T11:32:03.218942Z","iopub.status.idle":"2024-07-23T11:32:04.283243Z","shell.execute_reply.started":"2024-07-23T11:32:03.218910Z","shell.execute_reply":"2024-07-23T11:32:04.282488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=mpimg.imread('/kaggle/input/chess-positions/train/'+files[0])\nplt.imshow(img);#note that the shape is 400x400x3\n#print(img.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:05.348593Z","iopub.execute_input":"2024-07-23T11:32:05.348966Z","iopub.status.idle":"2024-07-23T11:32:05.723075Z","shell.execute_reply.started":"2024-07-23T11:32:05.348938Z","shell.execute_reply":"2024-07-23T11:32:05.722170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row=4\ncol=3\nplt.imshow(img[row*50:(row+1)*50,col*50:(col+1)*50,:]);","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:08.067690Z","iopub.execute_input":"2024-07-23T11:32:08.068080Z","iopub.status.idle":"2024-07-23T11:32:08.296271Z","shell.execute_reply.started":"2024-07-23T11:32:08.068051Z","shell.execute_reply":"2024-07-23T11:32:08.295365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parse the file names","metadata":{}},{"cell_type":"code","source":"PEN=files[0][:-5].split('-')\nprint(PEN)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:09.452865Z","iopub.execute_input":"2024-07-23T11:32:09.453180Z","iopub.status.idle":"2024-07-23T11:32:09.457998Z","shell.execute_reply.started":"2024-07-23T11:32:09.453155Z","shell.execute_reply":"2024-07-23T11:32:09.457062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's explicitly write 0 for each empty square. This will make it easier to identifty the position of the pieces","metadata":{}},{"cell_type":"code","source":"d={'1':'0','2':'00','3':'000','4':'0000','5':'00000','6':'000000','7':'0000000','8':'00000000'}\ntrans_table=str.maketrans(d)\ns=[item.translate(trans_table) for item  in PEN]\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:10.146069Z","iopub.execute_input":"2024-07-23T11:32:10.146379Z","iopub.status.idle":"2024-07-23T11:32:10.152420Z","shell.execute_reply.started":"2024-07-23T11:32:10.146355Z","shell.execute_reply":"2024-07-23T11:32:10.151577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we invert the transformation as follows","metadata":{}},{"cell_type":"code","source":"s1=s\nfor k, v in reversed(list(d.items())):\n    s1=[item.replace(v, k) for item in s1]\ns1","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:11.475351Z","iopub.execute_input":"2024-07-23T11:32:11.476046Z","iopub.status.idle":"2024-07-23T11:32:11.482276Z","shell.execute_reply.started":"2024-07-23T11:32:11.476016Z","shell.execute_reply":"2024-07-23T11:32:11.481437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We map pieces to ints by","metadata":{}},{"cell_type":"code","source":"map_to_ints={'n':0,'N':1,'b':2,'B':3,'r':4,'R':5,'p':6,'P':7,'k':8,'K':9,'q':10,'Q':11,'0':12}\nlabels=[map_to_ints[char] for char in s[0]]\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:12.845000Z","iopub.execute_input":"2024-07-23T11:32:12.845347Z","iopub.status.idle":"2024-07-23T11:32:12.852855Z","shell.execute_reply.started":"2024-07-23T11:32:12.845320Z","shell.execute_reply":"2024-07-23T11:32:12.851926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the reverse map from ints to characters","metadata":{}},{"cell_type":"code","source":"\nmap_from_ints=dict((v, k) for k, v in map_to_ints.items())\nx=[map_from_ints[k] for k in labels]\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:13.967421Z","iopub.execute_input":"2024-07-23T11:32:13.968375Z","iopub.status.idle":"2024-07-23T11:32:13.973318Z","shell.execute_reply.started":"2024-07-23T11:32:13.968343Z","shell.execute_reply":"2024-07-23T11:32:13.972421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define a model for classifying individual squares","metadata":{}},{"cell_type":"markdown","source":"We use the a similar toplogy to the MNIST digits problem i.e. 2 convolutional layers and 2 fully connected layers","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n      super(Net, self).__init__()\n\n      # First 2D convolutional layer. Takes in the 3x50x50 images\n      # outputting 32 convolutional features, with a square kernel size of 5\n      self.conv1 = nn.Conv2d(3, 32, 5)\n        \n      # Second 2D convolutional layer, taking in the 32 input layers,\n      # outputting 64 convolutional features, with a square kernel size of 5\n      self.conv2 = nn.Conv2d(32, 64, 5)\n\n      # Designed to ensure that adjacent pixels are either all 0s or all active\n      # with an input probability\n      self.dropout1 = nn.Dropout2d(0.25)\n      self.dropout2 = nn.Dropout(0.5)\n\n      # First fully connected layer\n      self.fc1 = nn.Linear(5184, 128)\n      # Second fully connected layer that outputs our 13 labels\n      self.fc2 = nn.Linear(128, 13)\n    \n    def forward(self, x):\n\n      x = self.conv1(x)               #Nx3x50x50 -> Nx32x46x46\n      x = F.relu(x) \n      x = F.max_pool2d(x, 2)            ##Nx32x46x46 -> Nx32x23x23\n\n      x = self.conv2(x)               #Nx32x23x23 -> Nx64x19x19\n      x = F.relu(x)\n      x = F.max_pool2d(x, 2)            ##Nx64x19x19 -> Nx64x9x9\n        \n      # Pass data through dropout1\n      x = self.dropout1(x)\n      # Flatten x with start_dim=1\n      x = torch.flatten(x, 1)\n      # Pass data through ``fc1``\n      x = self.fc1(x)\n      x = F.relu(x)\n      x = self.dropout2(x)\n      x = self.fc2(x)\n\n      # Apply softmax to x\n      #output = F.log_softmax(x, dim=1)# nn.CrossEntropyLoss() takes in logits\n      return x#output\n\nmy_nn = Net()\nprint(my_nn)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:15.514103Z","iopub.execute_input":"2024-07-23T11:32:15.514454Z","iopub.status.idle":"2024-07-23T11:32:15.555939Z","shell.execute_reply.started":"2024-07-23T11:32:15.514427Z","shell.execute_reply":"2024-07-23T11:32:15.555090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the model first","metadata":{}},{"cell_type":"code","source":"input=torch.tensor(img[0:50,0:50,:].transpose(2,0,1),dtype=torch.float32)/255# convert to tensor of floats\ninput=torch.unsqueeze(input,0)#batch dimension\nprint(input.shape)\nresult = my_nn(input)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:17.169357Z","iopub.execute_input":"2024-07-23T11:32:17.169679Z","iopub.status.idle":"2024-07-23T11:32:17.351526Z","shell.execute_reply.started":"2024-07-23T11:32:17.169655Z","shell.execute_reply":"2024-07-23T11:32:17.350661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set the optimizer","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(my_nn.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:19.137215Z","iopub.execute_input":"2024-07-23T11:32:19.138249Z","iopub.status.idle":"2024-07-23T11:32:20.440052Z","shell.execute_reply.started":"2024-07-23T11:32:19.138212Z","shell.execute_reply":"2024-07-23T11:32:20.439312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\nmy_nn.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:32:20.947953Z","iopub.execute_input":"2024-07-23T11:32:20.948334Z","iopub.status.idle":"2024-07-23T11:32:21.183368Z","shell.execute_reply.started":"2024-07-23T11:32:20.948310Z","shell.execute_reply":"2024-07-23T11:32:21.182527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs=30\naccuracy_train=np.zeros(n_epochs,)\nloss_train=np.zeros(n_epochs,)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:39:58.339910Z","iopub.execute_input":"2024-07-23T11:39:58.340500Z","iopub.status.idle":"2024-07-23T11:39:58.344788Z","shell.execute_reply.started":"2024-07-23T11:39:58.340468Z","shell.execute_reply":"2024-07-23T11:39:58.343829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"map_to_ints={'n':0,'N':1,'b':2,'B':3,'r':4,'R':5,'p':6,'P':7,'k':8,'K':9,'q':10,'Q':11,'0':12}\n\nN_samples=3000\n\nx_train=np.ndarray((64,3,50,50),np.uint8)\ny_train=np.ndarray((64,),np.uint8)\n\nall_predictions=np.ndarray((N_samples*64,),dtype='int64')\nall_labels=np.ndarray((N_samples*64,),dtype='int64')\n\n\nfor epoch in range(n_epochs):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i in range(0,N_samples):\n        img=mpimg.imread('/kaggle/input/chess-positions/train/'+files[i])\n        \n        s=files[i][:-5].replace('-','').translate(trans_table)\n        y_train=[map_to_ints[x] for x in s]\n        \n        j=0\n        for row in range(8):\n            for col in range(8):\n                x_train[j,:,:,:]=img[row*50:(row+1)*50,col*50:(col+1)*50,:].transpose(2,0,1)\n                j+=1\n                \n        batch=torch.tensor(x_train,dtype=torch.float32).to(device)/255\n        labels=torch.tensor(y_train,dtype=torch.long).to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = my_nn(batch)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n        # print statistics\n        running_loss += loss.item()\n        if i% 1000 == 0:\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n            \n\n#after each epoch, run again on the training data\n    with torch.no_grad():\n        \n        loss=0\n        for i in range(0,N_samples):\n            img=mpimg.imread('/kaggle/input/chess-positions/train/'+files[i])\n        \n            s=files[i][:-5].replace('-','').translate(trans_table)\n            y_train=[map_to_ints[x] for x in s]\n            all_labels[64*i:(64*(i+1))]=y_train\n        \n            j=0\n            for row in range(8):\n                for col in range(8):\n                    x_train[j,:,:,:]=img[row*50:(row+1)*50,col*50:(col+1)*50,:].transpose(2,0,1)\n                    j+=1\n                \n            batch=torch.tensor(x_train,dtype=torch.float32).to(device)/255\n            labels=torch.tensor(y_train,dtype=torch.long).to(device)\n\n            outputs = my_nn(batch)\n            loss += criterion(outputs, labels).item()\n            _, batch_predictions = torch.max(outputs.data, 1)\n            all_predictions[64*i:(64*(i+1))]=batch_predictions.cpu().numpy()\n            \n        \n        accuracy_train[epoch]=sum(all_labels==all_predictions)/all_labels.shape[0]\n        loss_train[epoch]=loss\n        \n\n    \n    print(f'[{epoch + 1}, {i + 1:5d}] training loss: {loss_train[epoch]}, training accuracy: {accuracy_train[epoch]}')\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T11:41:08.639604Z","iopub.execute_input":"2024-07-23T11:41:08.640299Z","iopub.status.idle":"2024-07-23T11:58:44.364846Z","shell.execute_reply.started":"2024-07-23T11:41:08.640270Z","shell.execute_reply":"2024-07-23T11:58:44.363963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfig,ax=plt.subplots(1,2,figsize=(12,4))\n\nsns.lineplot(pd.DataFrame({'loss':loss_train },index=range(n_epochs)),ax=ax[0]);\nax[0].set_yscale('log')\nax[0].set_ylabel('loss');\nax[0].set_xlabel('epochs');\n\nsns.lineplot(pd.DataFrame({'training':accuracy_train },index=range(n_epochs)),ax=ax[1]);\nax[1].set_ylim(0.98,1);\nax[1].set_ylabel('accuracy');\nax[1].set_xlabel('epochs');","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:05:24.890365Z","iopub.execute_input":"2024-07-23T12:05:24.890688Z","iopub.status.idle":"2024-07-23T12:05:25.564003Z","shell.execute_reply.started":"2024-07-23T12:05:24.890664Z","shell.execute_reply":"2024-07-23T12:05:25.563111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the model\nPATH = '/kaggle/working/my_nn.pth'\ntorch.save(my_nn.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:01:53.418912Z","iopub.execute_input":"2024-07-23T12:01:53.419244Z","iopub.status.idle":"2024-07-23T12:01:53.435086Z","shell.execute_reply.started":"2024-07-23T12:01:53.419219Z","shell.execute_reply":"2024-07-23T12:01:53.434055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the model\nPATH = '/kaggle/working/my_nn.pth'\nmy_nn = Net()\nmy_nn.load_state_dict(torch.load(PATH))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the model on the test data","metadata":{}},{"cell_type":"markdown","source":"Let's rerun on the test data","metadata":{}},{"cell_type":"code","source":"test_files=glob(\"*.jpeg\",root_dir='/kaggle/input/chess-positions/test/')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:02:01.094789Z","iopub.execute_input":"2024-07-23T12:02:01.095130Z","iopub.status.idle":"2024-07-23T12:02:01.787281Z","shell.execute_reply.started":"2024-07-23T12:02:01.095103Z","shell.execute_reply":"2024-07-23T12:02:01.786531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test=np.ndarray((64,3,50,50),np.uint8)\n\nN_test=1000 # first N_test images\n\nresults=np.ndarray((N_test,),np.bool_)\n\n\nfor j in range(N_test):\n    file=test_files[j]\n    img=mpimg.imread('/kaggle/input/chess-positions/test/'+file)\n    i=0\n    for row in range(8):\n        for col in range(8):\n            x_test[i,:,:,:]=img[row*50:(row+1)*50,col*50:(col+1)*50,:].transpose(2,0,1)\n            i+=1\n\n    with torch.no_grad():\n            batch=torch.tensor(x_test,dtype=torch.float32).to(device)/255\n            outputs = my_nn(batch)\n            _, batch_predictions = torch.max(outputs.data, 1)\n            p=[map_from_ints[k] for k in batch_predictions.cpu().numpy()]\n            s=[''.join(p[:8]),''.join(p[8:16]),''.join(p[16:24]),''.join(p[24:32]),''.join(p[32:40]),''.join(p[40:48]),''.join(p[48:56]),''.join(p[56:64])]        \n            PEN='-'.join(s)\n            for k, v in reversed(list(d.items())):\n                PEN=PEN.replace(v, k)\n            results[j]=file[:-5]==PEN\n            if results[j]==False:\n                print(file[:-5],PEN)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:04:49.694864Z","iopub.execute_input":"2024-07-23T12:04:49.695697Z","iopub.status.idle":"2024-07-23T12:04:54.563682Z","shell.execute_reply.started":"2024-07-23T12:04:49.695665Z","shell.execute_reply":"2024-07-23T12:04:54.562762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(results)/len(results)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:02:53.032749Z","iopub.execute_input":"2024-07-23T12:02:53.033080Z","iopub.status.idle":"2024-07-23T12:02:53.039623Z","shell.execute_reply.started":"2024-07-23T12:02:53.033055Z","shell.execute_reply":"2024-07-23T12:02:53.038630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is consistent with the single square training accuracy 0.9997^64=0.98. If we train on all 80000 test images, the accuracy may improve further but a more complex model may also be required","metadata":{}},{"cell_type":"markdown","source":"****Important lesson****","metadata":{}},{"cell_type":"markdown","source":"Since most of the chess board is empty, the empty squares dominate the dataset. One may think that it would be better to choose a balanced dataset on which to train. However, while this still leads to high test (and validation) accuracy on individual squares (as obtained here), the test acurracy is worse than expected (e.g. 90% rather than 98%). On inspection, the majority of the errors are due the mis-classification of empty squares and, in particular, empty squares that have high variance due to a non-uniform board pattern. Therefore it appears that the model has not seen sufficient empty squares to obtain the high test accuracy required. Since the test data is inherently unbalanced, it is makes sense to also train on the entire boards as we have done here. Then the obtained test accuracy on boards is consistent with the prediction test_accuracy**64","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}